from agents import Agent, Runner, AsyncOpenAI, OpenAIChatCompletionsModel, function_tool
from firecrawl import FirecrawlApp
from apify_client import ApifyClient
from agents.run import RunConfig
from elevenlabs import play
from elevenlabs.client import ElevenLabs
import chainlit as cl
import speech_recognition as sr  # <-- Added speech recognition for listening
import asyncio
import os

GEMINI_API_KEY= os.getenv("GEMINI_API_KEY")
LINKEDIN_SCRAPER_API_KEY= os.getenv("LINKEDIN_SCRAPER_API_KEY")
FIRECRAWL_API_KEY= os.getenv("FIRECRAWL_API_KEY")
ELEVENLABS_API_KEY= os.getenv("ELEVENLABS_API_KEY")

provider = AsyncOpenAI(
    api_key=GEMINI_API_KEY,
    base_url="https://generativelanguage.googleapis.com/v1beta/openai/"
)

model = OpenAIChatCompletionsModel(
    model='gemini-1.5-flash',
    openai_client=provider,
)

config = RunConfig(
    model=model,
    model_provider=provider
)

@function_tool
def linkedin_profile_scraper(linkedin_url):
    client = ApifyClient(LINKEDIN_SCRAPER_API_KEY)
    run_input = { "url": linkedin_url }
    run = client.actor("pratikdani/linkedin-people-profile-scraper").call(run_input=run_input)
    prospect_data = []
    for item in client.dataset(run["defaultDatasetId"]).iterate_items():
        prospect_data.append(item)
    return prospect_data

@function_tool
def web_scraper(company_url):
    app = FirecrawlApp(api_key=FIRECRAWL_API_KEY)
    scrape_result = app.scrape_url(url=company_url, formats=['markdown', 'html'])
    return scrape_result

precall_report_generator = Agent(
    name="Pre-Call Report Generator",
    instructions='''
    You are a Pre-Call Report Generator who uses tools and takes web_scraper output and linkedin_profile_scraper output and combines them
    and generates a pre-call report for sales rep to read before hopping on a call with the prospect.
    ''',
    tools=[web_scraper, linkedin_profile_scraper],
    model=model,
)

precall_report_generator_tool = precall_report_generator.as_tool(
    tool_name="precall_report_generator",
    tool_description='This is a Pre-call report generator tool.'
)

agent = Agent(
    name="Pre-Call Assistant",
    instructions='''
    You are a Pre-Call Assistant who calls tools based on the query. 
    When given a LinkedIn profile URL, you pass that url in the linkedin_profile_scraper tool parameters.Then you research and scrape the linkedin profile of the prospect.
    When given a website link/company url, you pass that url into the web_scraper parameter and scrape the info. Then you research and scrape the company/website info.
    When asked to generate a precall report, you generate a precall report using precall_report_generator_tool by combining the output generated by linkedin_profile_scraper and web_scraper.
    Give a structured output of the data.
    ''',
    tools=[linkedin_profile_scraper, web_scraper, precall_report_generator_tool],
    model=model,
)

voice_call_agent = Agent(
    name="Voice Caller Agent",
    instructions='''
    You are a sales agent making an outbound call to a prospect.
    You already have a pre-call report which contains important information about the prospect and their company.
    Use that information to guide your conversation and sell the product/service effectively.
    Talk in a conversational and friendly tone.
    don't generate a call script. wait for the person to respond, then talk again based on their response. 
    ''',
    model=model,
)

eleven_client = ElevenLabs(api_key=ELEVENLABS_API_KEY)

def listen_from_mic():
    recognizer = sr.Recognizer()
    with sr.Microphone() as source:
        print("\nðŸŽ¤ Listening... Speak now!")
        recognizer.adjust_for_ambient_noise(source)
        try:
            audio = recognizer.listen(source, timeout=10)
            query = recognizer.recognize_google(audio)
            print(f"ðŸŽ™ï¸ Recognized: {query}")
            return query
        except sr.UnknownValueError:
            print("Couldn't understand audio. Please try again.")
            return None
        except sr.RequestError:
            print("Speech recognition service error.")
            return None

@cl.on_chat_start
async def start():
    cl.user_session.set("history", [])
    await cl.Message(content="Hey! Going to hop on a call? Type your message or type /listen to talk!").send()

@cl.on_message
async def chat(message: cl.Message):
    history = cl.user_session.get("history") or []

    message_text = message.content.strip()

    # If user types /listen, capture voice input
    if message_text.lower() == "/listen":
        await cl.Message(content="ðŸŽ¤ Listening... Please speak now.").send()
        # Run blocking code in thread to avoid blocking event loop
        user_query = await asyncio.to_thread(listen_from_mic)
        if not user_query:
            await cl.Message(content="âŒ Couldn't recognize your speech. Try again or type your message.").send()
            return
        message_text = user_query
        await cl.Message(content=f"ðŸ—£ï¸ You said: {message_text}").send()

    history.append({"role": "user", "content": message_text})
    cl.user_session.set("history", history)

    msg = cl.Message(content="")
    await msg.send()

    # 1. Handle LinkedIn scraping
    if "linkedin.com" in message_text:
        result = Runner.run_streamed(agent, input=[{"role": "user", "content": message_text}], run_config=config)
        async for event in result.stream_events():
            if event.type == "raw_response_event" and hasattr(event.data, 'delta'):
                token = event.data.delta
                await msg.stream_token(token)
        cl.user_session.set("linkedin_data", result.final_output)
        await cl.Message(content="âœ… LinkedIn profile researched and saved.").send()
        return

    # 2. Handle company website scraping
    if "http" in message_text and "linkedin.com" not in message_text:
        result = Runner.run_streamed(agent, input=[{"role": "user", "content": message_text}], run_config=config)
        async for event in result.stream_events():
            if event.type == "raw_response_event" and hasattr(event.data, 'delta'):
                token = event.data.delta
                await msg.stream_token(token)
        cl.user_session.set("company_data", result.final_output)
        await cl.Message(content="âœ… Company website researched and saved.").send()
        return

    # 3. Handle generating the pre-call report
    if "generate" in message_text.lower() and "report" in message_text.lower():
        linkedin = cl.user_session.get("linkedin_data")
        company = cl.user_session.get("company_data")

        if not linkedin or not company:
            await cl.Message(content="âŒ Missing data. Please research both LinkedIn profile and company website first.").send()
            return

        combined_input = f"Hereâ€™s LinkedIn data:\n{linkedin}\n\nHereâ€™s company data:\n{company}\n\nGenerate a pre-call report."
        result = Runner.run_streamed(precall_report_generator, input=[{"role": "user", "content": combined_input}], run_config=config)
        async for event in result.stream_events():
            if event.type == "raw_response_event" and hasattr(event.data, 'delta'):
                token = event.data.delta
                await msg.stream_token(token)
        cl.user_session.set("precall_report", result.final_output)
        await cl.Message(content="âœ… Pre-call report generated and saved.").send()
        return

    # 4. Handle making the call
    if "call the prospect" in message_text.lower():
        precall_report = cl.user_session.get("precall_report")

        if not precall_report:
            await cl.Message(content="âŒ Pre-call report not found. Please generate it before making the call.").send()
            return

        result = Runner.run_streamed(voice_call_agent, input=[{"role": "user", "content": precall_report}], run_config=config)
        
        assistant_response = ""
        async for event in result.stream_events():
            if event.type == "raw_response_event" and hasattr(event.data, 'delta'):
                token = event.data.delta
                assistant_response += token
                await msg.stream_token(token)

        await cl.Message(content="ðŸ“ž Voice call simulation completed.").send()

        audio = eleven_client.text_to_speech.convert(
            text=assistant_response,
            voice_id="JBFqnCBsd6RMkjVDRZzb",
            model_id="eleven_multilingual_v2",
            output_format="mp3_44100_128",
        )
        play(audio)
        return

    # 5. Default behavior â€” run the main agent
    result = Runner.run_streamed(agent, input=history, run_config=config)
    async for event in result.stream_events():
        if event.type == "raw_response_event" and hasattr(event.data, 'delta'):
            token = event.data.delta
            await msg.stream_token(token)
    history.append({"role": "assistant", "content": result.final_output})
    cl.user_session.set("history", history)
